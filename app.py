# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •
import streamlit as st
import numpy as np
import pandas as pd
import re
import base64
import streamlit.components.v1 as components
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from PIL import Image
from io import BytesIO
from sklearn.impute import KNNImputer
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics.pairwise import euclidean_distances
from sklearn.preprocessing import RobustScaler

st.markdown(
    """
    <style>
    /* ìƒë‹¨ 'Made with Streamlit' ë¡œê³  ìˆ¨ê¹€ */
    header {visibility: hidden;}
    
    /* í•˜ë‹¨ footer ìˆ¨ê¹€ (ë²„íŠ¼ í¬í•¨) */
    footer {visibility: hidden;}
    
    /* íŠ¹ì • í´ë˜ìŠ¤ëª… ìš”ì†Œ ìˆ¨ê¹€ */
    ._profileContainer_gzau3_53 {display: none !important;}

    /* íŠ¹ì • í´ë˜ìŠ¤ëª… ìš”ì†Œ ìˆ¨ê¹€ */
    ._container_gzau3_1 _viewerBadge_nim44_23 {display: none !important;}
    </style>
    """,
    unsafe_allow_html=True
)


# í°íŠ¸ ì„¤ì •
font_path = "./NanumGothic.ttf"  # ë˜ëŠ” "./fonts/NanumGothic.ttf"
fontprop = fm.FontProperties(fname=font_path)
plt.rcParams['font.family'] = fontprop.get_name()
plt.rcParams['axes.unicode_minus'] = False

# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv("data_logistics.csv")
    df = df.rename(columns={"í˜„ì¥ëª…": "í”„ë¡œì íŠ¸ëª…"})
    return df

df_data = load_data()

st.markdown(
    """
    <div style="text-align: center; margin-bottom: 5px;">
        <img src="https://raw.githubusercontent.com/khj1637/dw-workday-ai/main/img/logo.png"
             alt="DongwonCI"
             width="180"
             style="display: block; margin: auto; padding-bottom: 5px;">
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <h1 style='text-align: center;'>ë¬¼ë¥˜ì„¼í„° ê³µì‚¬ê¸°ê°„ ì˜ˆì¸¡ê¸°</h1>
    <div style='height: 20px;'></div>  <!-- ê³µë°± í•œ ì¤„ -->
    <p style='text-align: left; font-size: 0.85rem; color: #555;'>
        ë²„ì „: v1.0.0<br>
        ìµœì¢… ì—…ë°ì´íŠ¸: 2025ë…„ 6ì›” 17ì¼<br>
        ê°œë°œì : ë™ì›ê±´ì„¤ì‚°ì—… ê¸°ìˆ íŒ€ ê¹€í˜ì§„
    </p>
    """,
    unsafe_allow_html=True
)

# 4. ë³´ì¡° í•¨ìˆ˜ë“¤

def detect_outlier_floors(floor_count):
    if floor_count >= 50:
        st.warning("âš ï¸ ì…ë ¥í•˜ì‹  ì¸µìˆ˜ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

def get_star_score(r2, std=None):
    score = r2 * 5
    if std is not None and std > 5:
        score -= 1
    score = max(0, min(5, score))
    return "â˜…" * int(round(score)) + "â˜†" * (5 - int(round(score)))

@st.cache_data
def knn_impute(df_input, n_neighbors=3):
    numeric_cols = df_input.select_dtypes(include=["float", "int"]).columns
    imputer = KNNImputer(n_neighbors=n_neighbors)
    df_filled = df_input.copy()
    df_filled[numeric_cols] = imputer.fit_transform(df_input[numeric_cols])
    return df_filled

# 5. ìœ ì‚¬ë„ ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜ (RandomForest ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì ìš©)
def find_similar_projects_with_categorical_filter(user_row, df, top_k=5):
    numeric_cols = ['ëŒ€ì§€ë©´ì ', 'ê±´ì¶•ë©´ì ', 'ì—°ë©´ì ', 'ì§€í•˜ì¸µìˆ˜', 'ì§€ìƒì¸µìˆ˜', 'í•˜ì—­ê°€ëŠ¥ì¸µìˆ˜', 'ìµœê³ ë†’ì´', 'ì „ì²´í† ê³µëŸ‰']
    structure_cols = [col for col in df.columns if col.startswith('êµ¬ì¡°í˜•ì‹_')]
    coldtype_cols = [col for col in df.columns if col.startswith('ì°½ê³ ìœ í˜•_')]

    input_values = user_row.iloc[0]
    available_numeric = [col for col in numeric_cols if col in input_values.index and pd.notnull(input_values[col])]
    if not available_numeric:
        raise ValueError("ì…ë ¥ê°’ì— ìœ íš¨í•œ ìˆ˜ì¹˜í˜• í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    selected_coldtypes = [col for col in coldtype_cols if col in user_row.columns and input_values[col] == 1]
    coldtype_mask = df[coldtype_cols].eq(0)
    for col in selected_coldtypes:
        coldtype_mask[col] = df[col].eq(1)
    coldtype_match = coldtype_mask.all(axis=1)
    df_matched = df[coldtype_match].dropna(subset=available_numeric).copy()

    if df_matched.empty:
        raise ValueError("ì…ë ¥í•œ ì°½ê³ ìœ í˜•ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    feature_cols = available_numeric + structure_cols
    df_model = df.dropna(subset=["ì „ì²´ê³µì‚¬ê¸°ê°„"])
    X_model = df_model[feature_cols]
    y_model = df_model["ì „ì²´ê³µì‚¬ê¸°ê°„"]
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_model, y_model)
    feature_importance = rf_model.feature_importances_
    weights = dict(zip(feature_cols, feature_importance))

    scaler = RobustScaler().fit(df_matched[feature_cols])
    df_scaled = scaler.transform(df_matched[feature_cols])
    user_scaled = scaler.transform(user_row[feature_cols])[0]

    def weighted_euclidean(a, b, w_dict, cols):
        return np.sqrt(np.sum([(a[i] - b[i]) ** 2 * w_dict[cols[i]] for i in range(len(cols))]))

    distances = np.array([weighted_euclidean(row, user_scaled, weights, feature_cols) for row in df_scaled])
    similarities = 1 / (distances + 1e-8)
    df_matched["ìœ ì‚¬ë„ì ìˆ˜"] = similarities * 100

    top_similar = df_matched.sort_values("ìœ ì‚¬ë„ì ìˆ˜", ascending=False).head(top_k)
    if "ì „ì²´ê³µì‚¬ê¸°ê°„" not in top_similar.columns or top_similar["ì „ì²´ê³µì‚¬ê¸°ê°„"].isnull().all():
        predicted_months = np.nan
    else:
        weighted_sum = (top_similar["ì „ì²´ê³µì‚¬ê¸°ê°„"] * top_similar["ìœ ì‚¬ë„ì ìˆ˜"]).sum()
        sum_weights = top_similar["ìœ ì‚¬ë„ì ìˆ˜"].sum()
        predicted_months = weighted_sum / sum_weights

    return top_similar, round(predicted_months, 1) if not np.isnan(predicted_months) else None

# 6. ì‚¬ìš©ì ì…ë ¥ê°’ íŒŒì‹± í•¨ìˆ˜ ì¶”ê°€
def parse_float(text):
    try:
        return float(text.replace(",", "").strip()) if text else np.nan
    except:
        return np.nan

def parse_int(text):
    try:
        return int(text.strip()) if text else np.nan
    except:
        return np.nan

# 7. ì‚¬ìš©ì ì…ë ¥ UI
with st.expander("í•„ìˆ˜ ì…ë ¥ê°’", expanded=True):
    
    # ğŸ‘‰ í”„ë¡œì íŠ¸ëª… ì…ë ¥ í•„ë“œ ì¶”ê°€
    

    col1, col2, col3 = st.columns(3)
    with col1:
        project_name = st.text_input("í”„ë¡œì íŠ¸ëª…")
        floors_below_str = st.text_input("ì§€í•˜ì¸µìˆ˜", placeholder="ì˜ˆ: 1")
        
    with col2:
        floors_above_str = st.text_input("ì§€ìƒì¸µìˆ˜", placeholder="ì˜ˆ: 4")
        land_area_str = st.text_input("ëŒ€ì§€ë©´ì  (ã¡)", placeholder="ì˜ˆ: 45085")
              
    with col3:
        building_area_str = st.text_input("ê±´ì¶•ë©´ì  (ã¡)", placeholder="ì˜ˆ: 26166")
        total_area_str = st.text_input("ì—°ë©´ì  (ã¡)", placeholder="ì˜ˆ: 70841")

    # ìˆ˜ì¹˜í˜• ë³€í™˜
    land_area = parse_float(land_area_str)
    building_area = parse_float(building_area_str)
    total_area = parse_float(total_area_str)
    floors_above = parse_int(floors_above_str)
    floors_below = parse_int(floors_below_str)

    detect_outlier_floors(floors_above)

    st.divider()
    st.markdown("#### ì°½ê³ ìœ í˜• (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)")
    usage_options = ['ìƒì˜¨', 'ì €ì˜¨', 'ëƒ‰ë™']
    selected_usages = []
    for i, u in enumerate(st.columns(len(usage_options))):
        if u.checkbox(usage_options[i], key=f"usage_{usage_options[i]}"):
            selected_usages.append(usage_options[i])

    st.markdown("#### êµ¬ì¡°í˜•ì‹ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)")
    structure_options = ['PC', 'RC', 'SRC', 'PEB']
    selected_structures = []
    for i, s in enumerate(st.columns(len(structure_options))):
        if s.checkbox(structure_options[i], key=f"struct_{structure_options[i]}"):
            selected_structures.append(structure_options[i])

with st.expander("ì„ íƒ ì…ë ¥ê°’", expanded=True):
    col4, col5, col6 = st.columns(3)
    with col4:
        excavation_volume_str = st.text_input("ì „ì²´ í† ê³µëŸ‰ (ã¥)", placeholder="ì˜ˆ: 120000")
    with col5:
        dockable_floors_str = st.text_input("í•˜ì—­ ê°€ëŠ¥ì¸µìˆ˜", placeholder="ì˜ˆ: 2")
    with col6:
        height_str = st.text_input("ìµœê³ ë†’ì´ (m)", placeholder="ì˜ˆ: 47.5")

    excavation_volume = parse_float(excavation_volume_str)
    dockable_floors = parse_int(dockable_floors_str)
    height = parse_float(height_str)

# 8. ì˜ˆì¸¡ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥

if st.button("ì˜ˆì¸¡ ì‹œì‘", use_container_width=True):
    # í•„ìˆ˜ ì…ë ¥ê°’ ëˆ„ë½ ì²´í¬
    required_fields = {
        "ëŒ€ì§€ë©´ì ": land_area,
        "ê±´ì¶•ë©´ì ": building_area,
        "ì—°ë©´ì ": total_area,
        "ì§€ìƒì¸µìˆ˜": floors_above,
        "ì§€í•˜ì¸µìˆ˜": floors_below,
        "ì°½ê³ ìœ í˜•": selected_usages,
        "êµ¬ì¡°í˜•ì‹": selected_structures
    }
    missing_fields = [k for k, v in required_fields.items() if (isinstance(v, list) and not v) or (not isinstance(v, list) and pd.isna(v))]
    if missing_fields:
        st.warning(f"âš ï¸ í•„ìˆ˜ ì…ë ¥ê°’ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_fields)} í•­ëª©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # ë…¼ë¦¬ì  ìœ íš¨ì„± ê²€ì‚¬
    logic_errors = []
    if building_area > land_area:
        logic_errors.append("ê±´ì¶•ë©´ì ì´ ëŒ€ì§€ë©´ì ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if total_area < building_area:
        logic_errors.append("ì—°ë©´ì ì´ ê±´ì¶•ë©´ì ë³´ë‹¤ ì‘ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if (floors_above + floors_below) == 0 and total_area > 0:
        logic_errors.append("ì¸µìˆ˜ê°€ ì—†ëŠ”ë° ì—°ë©´ì ì´ ì¡´ì¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    if total_area > 0 and building_area > 0 and floors_above > 0:
        estimated_total = building_area * (floors_above + floors_below)
        if total_area > estimated_total * 1.5:
            logic_errors.append("ì—°ë©´ì ì´ ê±´ì¶•ë©´ì Ã—ì¸µìˆ˜ë³´ë‹¤ ì§€ë‚˜ì¹˜ê²Œ í½ë‹ˆë‹¤. ì…ë ¥ê°’ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    if logic_errors:
        st.markdown("### âš ï¸ ì…ë ¥ê°’ ì˜¤ë¥˜ ê°ì§€")
        for err in logic_errors:
            st.error(f"ğŸš« {err}")
        st.stop()

    # ì‚¬ìš©ì ì…ë ¥ê°’ ì •ë¦¬
    user_input = {
        "ëŒ€ì§€ë©´ì ": land_area,
        "ê±´ì¶•ë©´ì ": building_area,
        "ì—°ë©´ì ": total_area,
        "ì§€ìƒì¸µìˆ˜": floors_above,
        "ì§€í•˜ì¸µìˆ˜": floors_below,
        "í•˜ì—­ê°€ëŠ¥ì¸µìˆ˜": dockable_floors if dockable_floors and dockable_floors > 0 else np.nan,
        "ìµœê³ ë†’ì´": height if height and height > 0 else np.nan,
        "ì „ì²´í† ê³µëŸ‰": excavation_volume if excavation_volume and excavation_volume > 0 else np.nan,
    }
    input_df = pd.DataFrame([user_input])
    for s in structure_options:
        input_df[f"êµ¬ì¡°í˜•ì‹_{s}"] = 1 if s in selected_structures else 0
    for u in usage_options:
        input_df[f"ì°½ê³ ìœ í˜•_{u}"] = 1 if u in selected_usages else 0

    # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
    user_corrected = input_df.copy()
    df_model = df_data.dropna(subset=["ì „ì²´ê³µì‚¬ê¸°ê°„"])
    feature_cols = user_corrected.columns.tolist()
    X_all = df_model[feature_cols].copy()
    y_all = df_model["ì „ì²´ê³µì‚¬ê¸°ê°„"]
    X_all = X_all.loc[:, X_all.isna().mean() <= 0.3]
    user_corrected = user_corrected[X_all.columns]

    # KNN ë³´ê°„
    X_all_imputed = knn_impute(X_all)

    # ì„ í˜•íšŒê·€
    model1 = LinearRegression().fit(X_all_imputed, y_all)
    pred1 = model1.predict(user_corrected)[0]
    r2_1 = model1.score(X_all_imputed, y_all)

    # ëœë¤í¬ë ˆìŠ¤íŠ¸
    model2 = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_all_imputed, y_all)
    pred2 = model2.predict(user_corrected)[0]
    r2_2 = model2.score(X_all_imputed, y_all)

    # ìœ ì‚¬ í”„ë¡œì íŠ¸ ê¸°ë°˜
    similar_df, pred3 = find_similar_projects_with_categorical_filter(user_corrected, df_data)
    sim_std = similar_df["ì „ì²´ê³µì‚¬ê¸°ê°„"].std()
    mean_similarity = similar_df["ìœ ì‚¬ë„ì ìˆ˜"].mean()

    # ì•™ìƒë¸”
    pred_ensemble = (pred1 * r2_1 + pred2 * r2_2 + pred3 * 1.0) / (r2_1 + r2_2 + 1.0)

    # ì‹ ë¢°ë„ ê²€ì‚¬
    warnings = []
    if sim_std > 6:
        warnings.append("ìœ ì‚¬ í”„ë¡œì íŠ¸ ê°„ ê³µì‚¬ê¸°ê°„ í¸ì°¨ê°€ ì»¤ì„œ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
    if mean_similarity < 25:
        warnings.append("ì…ë ¥ ì¡°ê±´ê³¼ ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ê°€ ì ì–´ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    if r2_1 < 0.3 and r2_2 < 0.3:
        warnings.append("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
    if warnings:
        st.markdown("### âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.")
        for w in warnings:
            st.error(f"ğŸš« {w}")
        st.info("ì…ë ¥ê°’ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ë³´ì™„í•œ í›„ ë‹¤ì‹œ ì˜ˆì¸¡ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
        st.stop()

    
    if project_name:
            # â­ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° ë° ë³„ì  ë³€í™˜
        trust_score = (r2_1 + r2_2 + 1.0) / 3
        star_rating = get_star_score(trust_score)
        
        st.markdown(f"""
            <div style="
                background-color: #f4f8fc;
                border: 1px solid #d0e3f1;
                border-radius: 12px;
                padding: 25px;
                margin-top: 20px;
                margin-bottom: 20px;
                box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.05);
            ">
                <div style="text-align: center; font-size: 1.6rem; font-weight: 700; color: #004080;">
                    ğŸ“Œ {project_name} ì‚°ì¶œ ê²°ê³¼
                </div>
                <div style="text-align: center; font-size: 2.4rem; font-weight: bold; color: #00264d; margin-top: 12px;">
                    {round(pred_ensemble, 1)} ê°œì›”
                </div>
                <div style="text-align: center; font-size: 0.95rem; color: #555; margin-top: 10px;">
                    ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ëŠ” <strong style="color:#004080;">ë¨¸ì‹ ëŸ¬ë‹ (ì„ í˜•íšŒê·€, ëœë¤í¬ë ˆìŠ¤íŠ¸)</strong>ê³¼
                    <strong style="color:#004080;">ìœ ì‚¬ í”„ë¡œì íŠ¸ ê¸°ë°˜</strong> ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.
                </div>
                <div style="text-align: center; font-size: 0.9rem; color: #444; margin-top: 8px;">
                    í•´ë‹¹ ì˜ˆì¸¡ ê²°ê³¼ì˜ <strong style="color:#004080;">ì‹ ë¢°ë„</strong>ëŠ” <span style="font-weight: bold;">{star_rating}</span> ì…ë‹ˆë‹¤.
                </div>
            </div>
        """, unsafe_allow_html=True)

    # ì˜ˆì¸¡ ê²°ê³¼ í‘œ
    st.subheader("â–  ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½")
    final_table = pd.DataFrame({
        "ì˜ˆì¸¡ ë°©ì‹": ["ì„ í˜•íšŒê·€", "ëœë¤í¬ë ˆìŠ¤íŠ¸", "ìœ ì‚¬ í”„ë¡œì íŠ¸ ê¸°ë°˜"],
        "ì˜ˆì¸¡ê°’ (ê°œì›”)": [round(pred1, 1), round(pred2, 1), round(pred3, 1)],
        "ì‹ ë¢°ë„": [
            get_star_score(r2_1),
            get_star_score(r2_2),
            get_star_score(1.0, sim_std)
        ]
    })
    st.dataframe(final_table)

    # ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµí‘œ
    if not similar_df.empty:
        st.subheader("â–  ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë˜í”„")

        fig, ax = plt.subplots(figsize=(10, 5))

        # íˆìŠ¤í† ê·¸ë¨: 1ê°œì›” ë‹¨ìœ„, ë¶€ë“œëŸ¬ìš´ ìŠ¤íƒ€ì¼
        min_month = int(similar_df["ì „ì²´ê³µì‚¬ê¸°ê°„"].min()) - 1
        max_month = int(similar_df["ì „ì²´ê³µì‚¬ê¸°ê°„"].max()) + 1
        bins = np.arange(min_month, max_month + 1)

        ax.hist(
            similar_df["ì „ì²´ê³µì‚¬ê¸°ê°„"],
            bins=bins,
            alpha=0.6,
            color='#cccccc',  # ì—°í•œ íšŒìƒ‰
            edgecolor='#888888',  # ì–´ë‘ìš´ í…Œë‘ë¦¬
            linewidth=1,
            label='ìœ ì‚¬ í”„ë¡œì íŠ¸ ë¶„í¬',
            align='mid'
        )

        # ì˜ˆì¸¡ê°’ ë¼ì¸
        ax.axvline(pred1, color='blue', linestyle='--', linewidth=1.2, label='ì„ í˜•íšŒê·€ ì˜ˆì¸¡')
        ax.axvline(pred2, color='green', linestyle='--', linewidth=1.2, label='ëœë¤í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡')
        ax.axvline(pred3, color='orange', linestyle='--', linewidth=1.2, label='ìœ ì‚¬ ê¸°ë°˜ ì˜ˆì¸¡')
        ax.axvline(pred_ensemble, color='red', linestyle='-', linewidth=2.5, label='ì•™ìƒë¸” ì˜ˆì¸¡')

        # ìŠ¤íƒ€ì¼ í–¥ìƒ
        ax.grid(axis='y', linestyle=':', linewidth=0.7, alpha=0.5)
        ax.set_facecolor('#f9f9f9')  # ë°ì€ íšŒìƒ‰ ë°°ê²½

        # í°íŠ¸ ë° ë ˆì´ì•„ì›ƒ
        ax.set_xticks(np.arange(min_month, max_month + 1, 1))
        ax.set_xlabel("ê³µì‚¬ê¸°ê°„", fontproperties=fontprop)
        ax.set_ylabel("ìœ ì‚¬ í”„ë¡œì íŠ¸ ìˆ˜", fontproperties=fontprop)
        ax.set_title("ê³µì‚¬ê¸°ê°„ ì˜ˆì¸¡ ê²°ê³¼ ë° ìœ ì‚¬ í”„ë¡œì íŠ¸ ë¶„í¬", fontproperties=fontprop)

        # ë²”ë¡€ í•˜ë‹¨ ê°€ë¡œ ì •ë ¬
        ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=5, prop=fontprop, frameon=False)

        st.pyplot(fig)

    
    # ğŸ“‰ ì‹ ë¢°ë„ ê¸°ë°˜ ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
    warnings = []

    # 1. ìœ ì‚¬ í”„ë¡œì íŠ¸ ê°„ ê³µì‚¬ê¸°ê°„ í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ í¬ë©´ â†’ ì‹ ë¢° ë‚®ìŒ
    if sim_std > 6:
        warnings.append("ìœ ì‚¬ í”„ë¡œì íŠ¸ ê°„ ê³µì‚¬ê¸°ê°„ í¸ì°¨ê°€ ì»¤ì„œ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")

    # 2. ìœ ì‚¬ë„ í‰ê· ì´ ë‚®ìœ¼ë©´ â†’ ìœ ì‚¬ ì‚¬ë¡€ê°€ ê±°ì˜ ì—†ìŒ
    mean_similarity = similar_df["ìœ ì‚¬ë„ì ìˆ˜"].mean()
    if mean_similarity < 25:
        warnings.append("ì…ë ¥ ì¡°ê±´ê³¼ ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ê°€ ì ì–´ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 3. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ RÂ² ì ìˆ˜ê°€ ë‘˜ ë‹¤ ë‚®ìœ¼ë©´ â†’ ì¼ë°˜í™” ì„±ëŠ¥ ë‚®ìŒ
    if r2_1 < 0.3 and r2_2 < 0.3:
        warnings.append("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì…ë ¥ê°’ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    # ì‹¤ì œ ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
    if warnings:
        st.markdown("### âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ ì£¼ì˜ì‚¬í•­")
        for w in warnings:
            st.warning(w)

    # ìœ ì‚¬ í”„ë¡œì íŠ¸ ë¦¬ìŠ¤íŠ¸
    st.subheader("â–  ì°¸ì¡°ëœ ìœ ì‚¬ í”„ë¡œì íŠ¸")
    if not similar_df.empty:
        display_df = similar_df.copy()

        def decode_types(row, prefix):
            cols = [col for col in row.index if col.startswith(prefix)]
            return " + ".join(col.replace(prefix, '') for col in cols if row[col] == 1)

        display_df["êµ¬ì¡°í˜•ì‹"] = display_df.apply(lambda row: decode_types(row, "êµ¬ì¡°í˜•ì‹_"), axis=1)
        display_df["ì°½ê³ ìœ í˜•"] = display_df.apply(lambda row: decode_types(row, "ì°½ê³ ìœ í˜•_"), axis=1)
        display_df["ì¸µìˆ˜"] = display_df.apply(
            lambda row: f"B{int(row['ì§€í•˜ì¸µìˆ˜']) if not pd.isna(row['ì§€í•˜ì¸µìˆ˜']) else 0} / "
                        f"{int(row['ì§€ìƒì¸µìˆ˜']) if not pd.isna(row['ì§€ìƒì¸µìˆ˜']) else 0}F",
            axis=1
        )

        display_df = display_df[[
            "í”„ë¡œì íŠ¸ëª…", "ì—°ë©´ì ", "ì¸µìˆ˜", "êµ¬ì¡°í˜•ì‹", "ì°½ê³ ìœ í˜•", "ì „ì²´ê³µì‚¬ê¸°ê°„"
        ]].rename(columns={
            "ì—°ë©´ì ": "ì—°ë©´ì  (ã¡)",
            "ì „ì²´ê³µì‚¬ê¸°ê°„": "ê³µì‚¬ê¸°ê°„ (ê°œì›”)"
        })

        st.dataframe(display_df)
        st.markdown("ğŸ“Œ **ì°¸ì¡°ëœ ìœ ì‚¬ í”„ë¡œì íŠ¸**ëŠ” ì…ë ¥ ì¡°ê±´ê³¼ ë²”ì£¼í˜• í•­ëª©ì´ ì¼ì¹˜í•œ ì‹¤ì œ ì‚¬ë¡€ë“¤ì…ë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ ìœ ì‚¬ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ê°’ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")


